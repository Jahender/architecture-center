---
title: Architecting Azure applications for resiliency and availability
description: 
author: 
ms.date: 03/25/2019
ms.topic: article
ms.service: architecture-center
ms.subservice: cloud-design-principles
ms.custom: 
---

# Architecting Azure applications for resiliency and availability

After you’ve developed the requirements for your application, the next step is to build resiliency and availability into it. This process starts with the following tasks:

-   [Conduct a failure mode analysis](#conduct-a-failure-mode-analysis)
-   [Plan for redundancy](#plan-for-redundancy)
-   [Design for scalability](#design-for-scalability)
-   [Determine subscription and service requirements](#determine-subscription-and-service-requirements)
-   [Load-balance as needed](#load-balance-as-needed)
-   [Implement resiliency strategies](#implement-resiliency-strategies)
-   [Ensure that availability meets SLAs](#ensure-that-availability-meets-slas)
-   [Manage your data](#manage-your-data)

## Conduct a failure mode analysis

The *failure mode analysis* (FMA) process builds resiliency into a system by identifying possible failure points in the system and defining how the application responds to those failures. The FMA should be part of the architecture and design phases, so failure recovery is built into the system from the beginning. The goals of an FMA are to:

-   Determine what types of failures an application might experience and how the application detects those failures.
-   Capture the potential effects of each type of failure and determine how the app responds.
-   Plan for logging and monitoring the failure and identify recovery strategies.

Table 1 provides examples of failure modes and detection strategies for a specific failure point—a call to an external web service/API.

Table 1. Failure modes and detection strategies

| Failure mode           | Detection strategy           |
|------------------------|------------------------------|
| Service is unavailable | HTTP 5xx                     |
| Throttling             | HTTP 429 (Too Many Requests) |
| Authentication         | HTTP 401 (Unauthorized)      |
| Slow response          | Request times out            |

For more information about the FMA process, with specific recommendations for Azure, see [Azure resiliency guidance: Failure mode analysis](https://docs.microsoft.com/en-us/azure/architecture/resiliency/failure-mode-analysis).

## Plan for redundancy

Failures vary in scope of impact. Some hardware failures, such as a failed disk, affect a single host machine. A failed network switch could affect an entire server rack. Less common failures, such as loss of power, disrupt a whole datacenter. Rarely, an entire region becomes unavailable.

Redundancy is one way to make an application resilient. The level of redundancy depends on your business requirements—not every application needs redundancy across regions to guard against a regional outage. In general, there’s a tradeoff between greater redundancy and reliability versus higher costs and complexity.

### Review Azure redundancy features

Azure has a number of redundancy features at every level of failure, from an individual virtual machine (VM) to an entire region.

-   **Single VMs** have an [uptime service level agreement (SLA)](https://azure.microsoft.com/support/legal/sla/virtual-machines) provided by Azure. (The VM must use premium storage for all operating system disks and data disks.) Although you can get a higher SLA by running two or more VMs, a single VM may be reliable enough for some workloads. For production workloads, however, we recommend using two or more VMs for redundancy.
-   **Availability sets** protect against localized hardware failures, such as a disk or network switch failing, by deploying two or more VMs in an availability set. VMs in an availability set are distributed across up to three fault domains that share a common power source and network switch. If     a hardware failure affects one fault domain, network traffic is routed to VMs in the other fault domains. For more information about availability sets, see [Manage the availability of Windows virtual machines in Azure](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/manage-availability).
-   **Availability Zones** are physically separate zones within an Azure region. Each Availability Zone has a distinct power source, network, and cooling. Deploying VMs across Availability Zones helps to protect an application against datacenter-wide failures. Not all regions support Availability Zones. For a list of supported regions and services, see [What are Availability Zones in Azure?](https://docs.microsoft.com/en-us/azure/availability-zones/az-overview) 
 
    If you are planning to use Availability Zones in your deployment, first validate that your application architecture and codebase support this configuration. If you are deploying commercial off-the-shelf software, consult with the software vendor and test adequately before deploying into production. An application must maintain state and prevent loss of data during an outage within the configured zone. The application must support running in an elastic and distributed infrastructure with no hard-coded
    infrastructure components specified in the codebase.
-   **Azure Site Recovery** replicates Azure Virtual Machines to another Azure region for business continuity (BC) and disaster recovery (DR) needs. You can conduct periodic DR drills to ensure that you meet the compliance needs. The VM is replicated with the specified settings to the selected region so you can recover your applications in the event of outages in the source region. For more information, see [Set up disaster recovery to a secondary Azure region for an Azure VM](https://docs.microsoft.com/en-us/azure/site-recovery/azure-to-azure-quickstart/).
 
    **Note** During testing, verify that the *recovery time objective* (RTO) and *recovery point objective* (RPO) metrics for your application meet your needs. RTO is the maximum acceptable time an application is unavailable after an incident, and RPO is the maximum acceptable duration of data loss during a disaster.
-   **Paired regions** are created using Azure Traffic Manager to distribute Internet traffic to different regions, protecting an application against a regional outage. Each Azure region is paired with another region. Together, these form a [*regional pair*](https://docs.microsoft.com/en-us/azure/best-practices-availability-paired-regions). To meet data residency requirements for tax and law enforcement jurisdiction purposes, regional pairs are located within the same geography (with the exception of Brazil South).

    To improve application resiliency, Azure serializes platform updates
    (planned maintenance) across each region pair, so only one paired region is
    updated at a time.
-   When you design a multiregion application, take into account that network latency across regions is higher than within a region. For example, if you are replicating a database to enable failover, use synchronous data replication within a region but asynchronous data replication across regions.

Table 2 Comparison of redundancy factors across several resiliency strategies

   |         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;      | **Availability set**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;      | **Availability Zone**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;       | **Azure Site Recovery/Paired region**                 |
|                  |                       |                          |                         |
|------------------|-----------------------|--------------------------|--------------------------------------|
| Scope of failure | Rack                  | Datacenter               | Region                               |
| Request routing  | Azure Load Balancer   | Cross-zone Load Balancer | Azure Traffic Manager                |
| Network latency  | Very low              | Low                      | Mid to high                          |
| Virtual network  | Azure Virtual Network | Virtual Network          | Cross-region Virtual Network peering |

### Complete Azure redundancy tasks

With those Azure features defined, you can move forward with the following tasks to meet redundancy requirements:

-   **Deploy multiple instances of services.** If your application depends on a single instance of a service, it creates a single point of failure. Provisioning multiple instances improves both resiliency and scalability. For [Azure App Service](https://docs.microsoft.com/en-us/azure/app-service/app-service-value-prop-what-is/), select an [App Service plan](https://docs.microsoft.com/en-us/azure/app-service/azure-web-sites-web-hosting-plans-in-depth-overview/) that offers multiple instances. For Azure Cloud Services, configure each of your roles to use [multiple instances](https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-choose-me/#scaling-and-management). For [Azure Virtual Machines](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-about/?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json), ensure that your VM architecture includes more than one VM and that each VM is included in an [availability set](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-manage-availability/).
-   **Use availability sets for each application tier.** Placing two or more VM instances in an availability set provides a higher [SLA](https://azure.microsoft.com/support/legal/sla/virtual-machines/).
-   **Replicate VMs using Azure Site Recovery.** When you replicate Azure VMs using [Site Recovery](https://docs.microsoft.com/en-us/azure/site-recovery/), all the VM disks are continuously replicated to the target region asynchronously. The recovery points are created every few minutes. This gives you an RPO in the order of minutes.
-   **Consider deploying your application across multiple regions.** If your application is deployed to a single region, in the rare event that the entire region becomes unavailable, your application will also be unavailable. This may be unacceptable under the terms of your application's SLA. If so, consider deploying your application and its services across multiple regions. A multiregion deployment can use an *active-active pattern* (distributing requests across multiple active instances) or an *active-passive pattern* (keeping a warm instance in reserve, in case the primary instance fails). We recommend that you deploy multiple instances of your application's services across regional pairs. For more information, see [Business continuity and disaster recovery (BCDR): Azure Paired Regions](https://docs.microsoft.com/en-us/azure/best-practices-availability-paired-regions).
-   **Use Azure Traffic Manager to route your application's traffic to different regions.** [Azure Traffic Manager](https://docs.microsoft.com/en-us/azure/traffic-manager/traffic-manager-overview/) performs load-balancing at the DNS level and routes traffic to different regions based on the [traffic routing](https://docs.microsoft.com/en-us/azure/traffic-manager/traffic-manager-routing-methods/) method you specify and on the health of your application's endpoints. Without Traffic Manager, you are limited to a single region for your deployment, which constrains scale, increases latency for some users, and causes application downtime, in the case of a region-wide service disruption.

## Design for scalability

*Scalability* is the ability of a system to handle increased load and is one of the [pillars of software quality](https://docs.microsoft.com/en-us/azure/architecture/guide/pillars). Scalability tasks during the architecting phase include:

-   **Partition workloads.** Design parts of the process to be discrete and decomposable. Minimize the size of each part, while following the usual rules for separation of concerns and the single responsibility principle. This allows the component parts to be distributed in a way that maximizes use of each compute unit (such as a role or database server). It also makes it easier to scale the application by adding instances of specific resources. For complex domains, consider adopting a [microservices architecture](https://docs.microsoft.com/en-us/azure/architecture/guide/architecture-styles/microservices).
-   **Design for scaling.** Scaling allows applications to react to variable load by increasing and decreasing the number of instances of roles, queues, and other services. However, the application must be designed with this in mind. For example, the application and the services it uses must be stateless to allow requests to be routed to any instance. This also prevents the addition or removal of specific instances from adversely impacting current users. You should also implement configuration or auto-detection of instances as they are added and removed, so that code in the application can perform the necessary routing. For example, a web application might use a set of queues in a round-robin approach to route requests to background services running in worker roles. The web application must be able to detect changes in the number of queues, to successfully route requests, and to balance the load on the application.
-   **Plan for growth with scale units.** For each resource, know the upper scaling limits, and use sharding or decomposition to go beyond those limits. Design the application so that it's easily scaled by adding one or more scale units. Determine the scale units for the system in terms of well-defined sets of resources. This makes applying scale-out operations easier and less prone to negative impact on the application through limitations imposed by lack of resources in some part of the overall system. For example, adding *X* number of web and worker roles might require *Y* number of additional queues and *Z* number of storage accounts to handle the additional workload. So a scale unit could consist of *X* web and worker roles, *Y* queues, and *Z* storage accounts.
-   **Avoid client affinity.** Where possible, ensure that the application doesn’t require affinity. Requests can then be routed to any instance, and the number of instances is irrelevant. This also avoids the overhead of storing, retrieving, and maintaining state information for each user.
-   **Take advantage of platform autoscaling features.** If the hosting platform supports an autoscaling capability, such as Azure Autoscale, prefer it to custom or third-party mechanisms unless the built-in mechanism can't fulfill your requirements. Use scheduled scaling rules, where possible, to ensure that resources are available without a startup delay, but add reactive autoscaling to the rules, where appropriate, to cope with unexpected changes in demand. For more information, see [Autoscaling guidance](https://docs.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling).  
 
    If your application isn’t configured to scale out automatically as load increases, it's possible that your application's services will fail if they become saturated with user requests. For more details, see the following:

    -   General: [Scalability checklist](https://docs.microsoft.com/en-us/azure/architecture/checklist/scalability)
    -   Azure App Service: [Scale instance count manually or automatically](https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/insights-how-to-scale/)
    -   Cloud Services: [How to autoscale a Cloud Service](https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-how-to-scale/)
    -   Virtual machines: [Automatic scaling and virtual machine scale sets](https://docs.microsoft.com/en-us/azure/virtual-machine-scale-sets/virtual-machine-scale-sets-autoscale-overview/)
-   **Offload intensive CPU/IO tasks as background tasks.** If a request to a service is expected to take a long time to run or may absorb considerable resources, offload the processing for this request to a separate task. Use worker roles or background jobs (depending on the hosting platform) to execute these tasks. This strategy enables the service to continue receiving further requests and to remain responsive. For more information, see [Background jobs guidance](https://docs.microsoft.com/en-us/azure/architecture/best-practices/background-jobs).
-   **Distribute the workload for background tasks.** If there are many background tasks or if the tasks require considerable time or resources, spread the work across multiple compute units (such as worker roles or background jobs). For one possible solution, see the [Competing Consumers pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/competing-consumers).
-   **Consider moving toward a *shared-nothing* architecture.** This architecture uses independent, self-sufficient nodes that have no single point of contention (such as shared services or storage). In theory, such a system can scale almost indefinitely. Although a fully shared-nothing approach is generally not practical for most applications, it may provide opportunities to design for better scalability. Good examples of moving toward a shared-nothing architecture include partitioning data and avoiding the use of server-side session state and client affinity.
-   **Design your application's storage requirements to fall within Azure Storage scalability and performance targets.** Azure Storage is designed to function within predefined scalability and performance targets, so design your application to utilize storage within those targets. If you exceed these targets, your application will experience storage throttling. To fix this, provision additional storage accounts. If you run up against the storage account limit, provision additional Azure subscriptions and then provision additional storage accounts there. For more information, see [Azure Storage scalability and performance targets](https://docs.microsoft.com/en-us/azure/storage/storage-scalability-targets/).
-   **Select the right VM size for your application.** Measure the actual CPU, memory, disk, and I/O of your VMs in production, and verify that the VM size you've selected is sufficient. If not, your application may experience capacity issues as the VMs approach their limits. VM sizes are described in detail in [Sizes for virtual machines in Azure](https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-sizes/?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).

## Determine subscription and service requirements

Choose the right subscription and service features for your app by working
through these tasks:

-   **Evaluate requirements against [Azure subscription and service limits](https://docs.microsoft.com/en-us/azure/azure-subscription-service-limits/).** *Azure subscriptions* have limits on certain resource types, such as number of resource groups, cores, and storage accounts. If your application requirements exceed Azure subscription limits, create another Azure subscription and provision sufficient resources there. Individual Azure services have consumption limits—for example, limits on storage, throughput, number of connections, requests per second, and other metrics. Your application will fail if it attempts to use resources beyond these limits, resulting in service throttling and possible downtime for affected users. Depending on the specific service and your application requirements, you can often avoid these limits by scaling up (for example, choosing another pricing tier) or scaling out (such as adding new instances).
-   **Determine how many storage accounts you need.** Azure allows a specific number of storage accounts per subscription. For more information, see [Azure subscription and service limits, quotas, and constraints](https://docs.microsoft.com/en-us/azure/azure-subscription-service-limits/#storage-limits).
-   **Select the right service tier for Azure SQL Database.** If your application uses Azure SQL Database, ensure that you have selected the appropriate service tier. If you select a tier that is not able to handle your application's database transaction unit (DTU) requirements, your data use will be throttled. For more information on selecting the correct service plan, see [SQL Database options and performance: Understand what's available in each service tier](https://docs.microsoft.com/en-us/azure/sql-database/sql-database-service-tiers/).

## Load-balance as needed

Proper load-balancing allows you to meet availability requirements and to minimize costs associated with availability. Consider the following tasks:

-   **Use load-balancing to distribute requests.** Load-balancing distributes your application's requests to healthy service instances by removing unhealthy instances from rotation. If your service uses Azure App Service or Azure Cloud Services, it’s already load-balanced for you. However, if your application uses Azure VMs, you need to provision a load-balancer. See the [Azure Load Balancer](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-overview/) overview for more details.  
      
    You can use Azure Load Balancer to:

    -   Load-balance incoming Internet traffic to your VMs. This configuration is known as a [*public Load Balancer*](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-overview#publicloadbalancer).
    -   Load-balance traffic across VMs inside a virtual network. You can also reach a Load Balancer front end from an on-premises network in a hybrid scenario. Both scenarios use a configuration that is known as an [*internal Load Balancer*](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-overview#internalloadbalancer).
    -   Port forward traffic to an itemized port on specific VMs with inbound network address translation (NAT) rules.
    -   Provide [outbound connectivity](https://docs.microsoft.com/en-us/azure/load-balancer/load-balancer-outbound-connections) for VMs inside your virtual network by using a public Load Balancer.

-   **Configure Azure Application Gateway to use multiple instances.** Depending on your application's requirements, an [Azure Application Gateway](https://docs.microsoft.com/en-us/azure/application-gateway/application-gateway-introduction/) may be better suited to distributing requests to your application's services. However, single instances of the Application Gateway service are not guaranteed by an SLA, so it's possible that your application could fail if the Application Gateway instance fails. Provision more than one medium or larger instance to guarantee availability of the service under the terms of the [Application Gateway SLA](https://azure.microsoft.com/support/legal/sla/application-gateway/).
-   **Balance loads across regions with a traffic manager, such as Azure Traffic Manager.** To load-balance traffic across regions requires a traffic management solution, and Azure provides [Traffic Manager](https://azure.microsoft.com/services/traffic-manager/). You can also take advantage of third-party services that provide similar traffic-management capabilities.

## Implement resiliency strategies

The tasks in this section can help you design some common resiliency strategies. Most of these strategies are not limited to a particular technology. The descriptions summarize the general idea behind each technique and include links to further reading.

-   **Implement resiliency patterns** for remote operations, where appropriate. If your application depends on communication between remote services, follow [design patterns](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/resiliency) for dealing with transient failures.

-   **Retry transient failures.** These can be caused by momentary loss of network connectivity, a dropped database connection, or a timeout when a service is busy. Often, a transient failure can be resolved by simply retrying the request.

    -   For many Azure services, the client software development kit (SDK) implements automatic retries in a way that is transparent to the caller. See [Retry guidance for specific services](https://docs.microsoft.com/en-us/azure/architecture/best-practices/retry-service-specific).
    -   Or implement the [Retry pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/retry) to help the application handle anticipated, temporary failures transparently when it tries to connect to a service or network resource.

-   **Use a circuit breaker** to handle faults that might take a variable amount of time to fix when connecting to a remote service or resource. The [Circuit Breaker pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/circuit-breaker) can prevent an application from repeatedly trying an operation that is likely to fail. The circuit breaker wraps calls to a service and tracks the number of recent failures. If the failure count exceeds a threshold, the circuit breaker starts returning an error code without calling the service. This gives the service time to recover and helps avoid cascading failures.
-   **Isolate critical resources.** Failures in one subsystem can sometimes cascade, resulting in failures in other parts of the application. This can happen if a failure prevents some resources, such as threads or sockets, from getting freed in a timely manner, leading to resource exhaustion. To avoid this, you can partition a system into isolated groups so that a failure in one partition does not bring down the entire system.

    Here are some examples of this technique, which is sometimes called the [Bulkhead pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/bulkhead):

    -   Partition a database (for example, by tenant), and assign a separate pool of web server instances for each partition.
    -   Use separate thread pools to isolate calls to different services. This helps to prevent cascading failures if one of the services fails. For an example, see the Netflix [Hystrix library](https://medium.com/netflix-techblog/introducing-hystrix-for-resilience-engineering-13531c1ab362).
    -   Use [containers](https://en.wikipedia.org/wiki/Operating-system-level_virtualization) to limit the resources available to a particular subsystem.

        ![Diagram of the Bulkhead pattern](_images/bulkhead.png)

  
-   **Apply [*compensating transactions*](https://docs.microsoft.com/en-us/azure/architecture/patterns/compensating-transaction).** These are transactions that undo the effects of another completed transaction. In a distributed system, it can be difficult to achieve strong transactional consistency. Compensating transactions can help to achieve consistency by using a series of smaller, individual transactions that can be undone at each step. For example, to book a trip, a customer might reserve a car, a hotel room, and a flight. If one of these steps fails, the entire operation fails. Instead of trying to use a single distributed transaction for the entire operation, you can define a compensating transaction for each step.
-   **Implement asynchronous operations, whenever possible.** Synchronous operations can monopolize resources and block other operations while the caller waits for the process to complete. Design each part of your application to allow for asynchronous operations, whenever possible. For more information on how to implement asynchronous programming in C\#, see [Asynchronous Programming with keywords **async** and **await**](https://docs.microsoft.com/en-us/dotnet/articles/csharp/async).

## Ensure that availability meets SLAs

*Availability* is the proportion of time that a system is functional and working, and it is one of the [pillars of software quality](https://docs.microsoft.com/en-us/azure/architecture/guide/pillars). Use the tasks in this section to review your application architecture from an availability standpoint to make sure that your availability meets your SLAs.

-   **Avoid any single point of failure.** All components, services, resources, and compute instances should be deployed as multiple instances to prevent a single point of failure from affecting availability. This includes authentication mechanisms. Design the application to be configurable to use multiple instances and to automatically detect failures and redirect requests to non-failed instances, if the platform doesn’t do this automatically.
-   **Decompose workloads by service-level objective.** If a service is composed of critical and less-critical workloads, manage them differently and specify the service features and number of instances to meet their availability requirements.
-   **Minimize and understand service dependencies.** Minimize the number of different services used, where possible, and ensure that you understand all the feature and service dependencies that exist in the system. This includes the nature of these dependencies and the impact of failure or reduced performance in each one on the overall application.
-   **Design tasks and messages to be *idempotent*, where possible.** An operation is idempotent if it can be repeated multiple times and produce the same result. This can ensure that duplicated requests don't cause problems. Message consumers and the operations they carry out should be idempotent so that repeating a previously executed operation does not render the results invalid. This may mean detecting duplicated messages or ensuring consistency by using an optimistic approach to handling conflicts.
-   **Configure request timeouts.** Services and resources may become unavailable, causing requests to fail. Ensure that the timeouts you apply are appropriate for each service or resource and for the client that is accessing them. In some cases, you might allow a longer timeout for a particular instance of a client, depending on the context and other actions that the client is performing. Very short timeouts may cause excessive retry operations for services and resources that have considerable latency. Very long timeouts can cause blocking, if a large number of requests are queued, waiting for a service or resource to respond.
-   **Use a message broker that implements high availability for critical transactions.** Many cloud applications use messaging to initiate tasks that are performed synchronously. To guarantee delivery of messages, the messaging system should provide high availability. [Azure Service Bus messaging](https://docs.microsoft.com/en-us/azure/service-bus-messaging) implements *at least once* semantics, which means that a message posted to a queue is not lost, although duplicate copies may be delivered under certain circumstances. If message processing is idempotent (see the previous item), repeated delivery should not be a problem.
-   **Throttle high-volume users.** Sometimes, a small number of users creates excessive load. This can have an impact on other users and can reduce the overall availability of your application. When a single client makes an excessive number of requests, the application might throttle the client for a certain period. During the throttling period, the application refuses some or all of the requests from that client. The threshold for throttling often depends on the customer's service tier.  
 
    Throttling does not imply that the client was necessarily acting maliciously—only that it exceeded its service quota. In some cases, a consumer might consistently exceed their quota or otherwise behave badly. In that case, you might go further and block the user. Typically, this is done by blocking an API key or an IP address range. For more information, see [Throttling pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/throttling).
-   **Design applications to gracefully degrade.** The load on an application may exceed the capacity of one or more parts, causing reduced availability and failed connections. Scaling can help to alleviate this, but it may reach a limit imposed by other factors, such as resource availability or cost. When an application reaches a resource limit, it should take appropriate action to minimize the impact for the user. For example, in an e-commerce system, if the order-processing subsystem is under strain or fails, it can be temporarily disabled while allowing other functionality, such as browsing the product catalog. It might be appropriate to postpone requests to a failing subsystem—for example, still enabling customers to submit orders but saving them for later processing, when the orders subsystem is available again.
-   **Gracefully handle rapid burst events.** Most applications need to handle varying workloads over time. Autoscaling can help to handle the load, but it may take some time for additional instances to come online and handle requests. To prevent sudden and unexpected bursts of activity from overwhelming the application, design it to queue requests to the services it uses and to degrade gracefully when queues are near capacity. Ensure that there is sufficient performance and capacity available under non-burst conditions to drain the queues and to handle outstanding requests. For more information, see the [Queue-Based Load Leveling pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/queue-based-load-leveling).
-   **Compose or fail back to multiple components.** Design applications to use multiple instances without affecting operation and existing connections, where possible. To maximize availability, use multiple instances and distribute requests between them, and detect and avoid sending requests to failed instances.
-   **Fail back to a different service or workflow.** For example, if writing to SQL Database fails, temporarily store data in Blob storage or Redis Cache. Provide a way to replay the writes to SQL Database when the service becomes available. In some cases, a failed operation may have an alternative action that allows the application to continue to work, even when a component or service fails. If possible, detect failures and redirect requests to other services that can offer a suitable alternative functionality or to backup or reduced functionality instances that can maintain core operations while the primary service is offline.
-   **Use load leveling to smooth out spikes in traffic.** Applications may experience sudden spikes in traffic, which can overwhelm services on the back end. If a back-end service cannot respond to requests quickly enough, it may cause requests to queue (back up) or throttle the application. To avoid this, you can use a queue as a buffer. When there is a new work item, instead of calling the back-end service immediately, the application queues a work item to run asynchronously. The queue acts as a buffer that smooths out peaks in the load. For more information, see [Queue-Based Load Leveling pattern](https://docs.microsoft.com/en-us/azure/architecture/patterns/queue-based-load-leveling).

## Manage your data

How you manage your data plays directly into the availability of your application. The tasks in this section can assist you in creating a management plan to help ensure availability, including backing up your data and planning for disaster recovery.

-   **Replicate data and understand the replication methods for your application's data sources.** Replicating data is a general strategy for handling non-transient failures in a data store. It's important to consider both the read and write paths. Depending on the storage technology, you might have multiple writable replicas or you might have a single writable replica and multiple read-only replicas. To maximize availability, replicas can be placed in multiple regions. However, this increases the latency when replicating the data. Typically, replicating across regions is done asynchronously, which implies an eventual consistency model and potential data loss if a replica fails.  
      
    You can use [Azure Site Recovery](https://docs.microsoft.com/en-us/azure/site-recovery/azure-to-azure-quickstart/) to replicate Azure Virtual Machines from one region to another. Site Recovery replicates data continuously to the target region. When an outage occurs at your primary site, you fail over to a secondary location.
-   **Ensure that no single user account has access to both production and backup data.** Your data backups are compromised if one single user account has permission to write to both production and backup sources. A malicious user could purposely delete all your data, and a regular user could accidentally delete it. Design your application to limit the permissions of each user account so that only the users that require write access have write access and so that it's only to either production or backup, but not both.
-   **Document and test your data source failover and failback process.** If your data source fails catastrophically, a human operator follows a set of documented instructions to fail over to a new data source. If the documented steps have errors, an operator won’t be able to successfully follow them and to fail over the resource. Regularly test the instruction steps to verify that an operator who follows the documentation can successfully fail over and fail back the data source.
-   **Back up your data and validate your data backups.** Regularly run a script to validate data integrity, schema, and queries to ensure that backup data is what you expect. Log and report any inconsistencies so the backup service can be repaired.
-   **Use periodic backup and point-in-time restore.** Regularly and automatically back up data that is not preserved elsewhere, and verify that you can reliably restore both the data and the application itself if failure occurs. Ensure that backups meet your RPO. Data replication is not a backup feature because human error or malicious operations can corrupt data across all the replicas. The backup process must be secure to protect the data in transit and in storage. Databases or parts of a data store can usually be recovered to a previous point in time by using transaction logs. For more information, see [Recover from data corruption or accidental deletion](https://docs.microsoft.com/en-us/azure/architecture/resiliency/recovery-data-corruption).
-   **Consider using a geo-redundant storage account.** Data stored in an Azure Storage account is always replicated locally. However, there are multiple replication strategies to choose from when a storage account is provisioned. To protect your application data against the rare case when an entire region becomes unavailable, select [Azure Read-Access Geo-Redundant Storage (RA-GRS)](https://docs.microsoft.com/en-us/azure/storage/storage-redundancy/#read-access-geo-redundant-storage).  
      
    **Note** For VMs, do not rely on RA-GRS replication to restore the VM disks (VHD files). Instead, use [Azure Backup](https://docs.microsoft.com/en-us/azure/backup).

-   **Consider using the Reference Data pattern to deploy *reference data* to multiple regions.** Reference data is read-only data that supports application functionality. It typically doesn’t change often. Although backup and restore is one method to handle region-wide service disruptions, the RTO is relatively long. When you deploy the application to a secondary region, some strategies can improve the RTO for reference data.  
      
    Because reference data changes infrequently, you can improve the RTO by maintaining a permanent copy of the reference data in the secondary region. This eliminates the time required to restore backups in the event of a disaster. To meet the multiple-region disaster recovery requirements, you must deploy the application and the reference data together in multiple regions. You can deploy reference data to the role itself, to external storage, or to a combination of both.

-   **Use optimistic concurrency and eventual consistency.** Transactions that block access to resources through locking (*pessimistic concurrency*) can cause poor performance and can considerably reduce availability. These problems can become especially acute in distributed systems. In many cases, careful design and techniques, such as partitioning, can minimize the chances of conflicting updates occurring. If data is replicated or is read from a separately updated store, the data will only be eventually consistent. But the advantages usually far outweigh the impact on availability of using transactions to ensure immediate consistency.
-   **Use active geo-replication for SQL Database to replicate changes to a secondary database in the same or a different region.** Active geo-replication for SQL Database automatically replicates database changes to secondary databases in the same Azure region or even in a different Azure region. This provides a potential alternative to some of the more manual data synchronization techniques. For more information, see [Overview: SQL Database Active Geo-Replication.](https://github.com/uglide/azure-content/blob/master/articles/sql-database/sql-database-geo-replication-overview.md)
-   **Use the DATABASE COPY command to create a backup copy, or use the Azure SQL Database import/export service to export databases to BACPAC files** (alternative to active geo-replication).

    -   **SQL Database.** You can also use a more manual approach for backup and restore. Use the **DATABASE COPY** command to create a backup copy of the database with transactional consistency. You can also use the import/export service of Azure SQL Database, which supports exporting databases to BACPAC files (compressed files containing your database schema and associated data) that are stored in Azure Blob storage.  
          
        The built-in redundancy of Azure Storage creates two replicas of the backup file in the same region. However, the frequency of running the backup process determines your RPO, which is the amount of data you might lose in disaster scenarios. For example, imagine that you perform a backup at the top of each hour, and a disaster occurs two minutes before the top of the hour. You lose 58 minutes of data recorded after the last backup was performed. Also, to protect against a region-wide
        service disruption, you should copy the BACPAC files to an alternate region. You then have the option of restoring those backups there. For more details, see [Overview: Cloud business continuity and database disaster recovery with SQL Database](https://github.com/rgl/azure-content/blob/master/articles/sql-database/sql-database-business-continuity.md).

    -   **SQL Data Warehouse.** For SQL Data Warehouse, use [geo-backups](https://docs.microsoft.com/en-us/azure/sql-data-warehouse/backup-and-restore) to restore to a paired region for disaster recovery. These backups are taken every 24 hours and can be restored within 20 minutes in the paired region. This feature is on by default for all SQL Data Warehouse instances. For more information on how to restore your data warehouse, see [Restore from an Azure geographical region using PowerShell.](https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-restore)

-   **Replicate VM disks using Azure Site Recovery.** When you replicate Azure VMs using [Site Recovery](https://docs.microsoft.com/en-us/azure/site-recovery/), all the VM
    disks are continuously replicated to the target region asynchronously. The recovery points are created every few minutes. This gives you an RPO in the order of minutes.
-   **Backup SQL Server running on VMs or configure a log-shipping session.** For SQL Server running on VMs, there are two options: traditional backups and log shipping. Traditional backups enable you to restore to a specific point in time, but the recovery process is slow. Restoring traditional backups requires that you start with an initial full backup and then apply any backups taken after that. The second option is to configure a log-shipping session to delay the restore of log backups (for example, by two hours). This provides a window to recover from errors made on the primary.
-   **Use a custom process or third-party tool for Azure Storage backup.** For Azure Storage, you can develop a custom backup process or use a third-party backup tool. Note that most application designs have additional complexities, in which storage resources reference each other. For example, consider a SQL database with a column that links to a blob in Azure Storage. If the backups do not happen simultaneously, the database might have a pointer to a blob that was not backed up before the failure. The application or disaster recovery plan must implement processes to handle this inconsistency after a recovery.
-   **Use native integration–based replication or snapshotting capabilities for other infrastructure-as-a-service–hosted (IaaS-hosted) data platforms.** Other IaaS-hosted data platforms, such as Elasticsearch or MongoDB, have their own capabilities and considerations when creating an integrated backup and restore process. For these data platforms, the general recommendation is to use any native or available integration-based replication or snapshotting capabilities. If those capabilities do not exist or are not suitable, consider using Azure Backup service or managed/unmanaged disk snapshots to create a point-in-time copy of application data. In all cases, it’s important to determine how to achieve consistent backups, especially when application data spans multiple files systems or when multiple drives are combined into a single file system using volume managers or a software-based redundant array of independent disks (RAID).
-   **Understand the replication methods for your application's data sources.** Your application data will be stored in different data sources and will have varied availability requirements. Evaluate the replication methods for each type of data storage in Azure, including [Azure Storage redundancy](https://docs.microsoft.com/en-us/azure/storage/storage-redundancy/) and [SQL Database active geo-replication](https://docs.microsoft.com/en-us/azure/sql-database/sql-database-geo-replication-overview/) to ensure that your application's data requirements are satisfied. If you replicate Azure VMs using [Site Recovery](https://docs.microsoft.com/en-us/azure/site-recovery/), all the VM disks are continuously replicated to the target region asynchronously. The recovery points are created every few minutes.
-   **Establish data strategies for disaster recovery.** Proper data handling is a challenging aspect of any disaster recovery plan. During the recovery process, data restoration typically takes the most time. Different choices for reducing functionality result in difficult challenges for data recovery from failure and for consistency after failure.  
      
    One consideration is the need to restore or maintain a copy of the application’s data. This data is used for reference and transactional purposes at a secondary site. An on-premises deployment requires an expensive and lengthy planning process to implement a multiregion disaster recovery strategy. Conveniently, most cloud providers, including Azure, readily allow the deployment of applications to multiple regions. These regions are geographically distributed in such a way that multiregion
    service disruption should be extremely rare. The strategy for handling data across regions is one of the contributing factors for the success of any disaster recovery plan.
